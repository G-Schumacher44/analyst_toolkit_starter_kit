# ------------------------------------------------------------------------------
# 📄 Config File: run_duplicates_config.yaml
# 🧩 Module: Duplicates (M04)
# 📌 Purpose: Detects and handles duplicate rows based on configured logic.
# ------------------------------------------------------------------------------
# This module can flag or remove duplicates depending on the `mode` setting.
# ------------------------------------------------------------------------------

# 📥 Execution context
notebook_mode: true
run_id: ""
logging: "auto"             # Options: 'on', 'off', or 'auto'

# 🔎 Duplicate detection settings
duplicates:
  run: true

  # 🎯 Target subset (null = use all columns)
  subset_columns: null

  # 🧭 Deduplication logic
  keep: "first"           # Options: 'first', 'last', or False
  mode: "remove"          # Options: 'remove', 'flag'

  # 📂 Input source
  input_path: "exports/joblib/{run_id}_m02_2_df_certified.joblib"

  # ⚙️ Operational settings (required by pipeline)
  settings:
    checkpoint: true
    checkpoint_path: "exports/joblib/{run_id}/{run_id}_m04__dupes_checkpoint.joblib"

    export: true
    export_path: "exports/reports/duplicates/duplicates_report.xlsx"
    export_format: "xlsx"

    show_inline: true

    plotting:
      run: true
      save_dir: "exports/plots/duplicates/"

  # 🧼 Optional preview cleanup for schema-variant files
  preview_drop_columns:
    - "timestamp"
    - "script_name"
    - "user"