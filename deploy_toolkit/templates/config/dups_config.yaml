# ------------------------------------------------------------------------------
# ğŸ“„ Config File: run_duplicates_config.yaml
# ğŸ§© Module: Duplicates (M04)
# ğŸ“Œ Purpose: Detects and handles duplicate rows based on configured logic.
# ------------------------------------------------------------------------------
# This module can flag or remove duplicates depending on the `mode` setting.
# ------------------------------------------------------------------------------

# ğŸ“¥ Execution context
notebook_mode: true
run_id: ""
logging: "auto"             # Options: 'on', 'off', or 'auto'

# ğŸ” Duplicate detection settings
duplicates:
  run: true

  # ğŸ¯ Target subset (null = use all columns)
  subset_columns: null

  # ğŸ§­ Deduplication logic
  keep: "first"           # Options: 'first', 'last', or False
  mode: "remove"          # Options: 'remove', 'flag'

  # ğŸ“‚ Input source
  input_path: "exports/joblib/{run_id}_m02_2_df_certified.joblib"

  # âš™ï¸ Operational settings (required by pipeline)
  settings:
    checkpoint: true
    checkpoint_path: "exports/joblib/{run_id}/{run_id}_m04__dupes_checkpoint.joblib"

    export: true
    export_path: "exports/reports/duplicates/duplicates_report.xlsx"
    export_format: "xlsx"

    show_inline: true

    plotting:
      run: true
      save_dir: "exports/plots/duplicates/"

  # ğŸ§¼ Optional preview cleanup for schema-variant files
  preview_drop_columns:
    - "timestamp"
    - "script_name"
    - "user"