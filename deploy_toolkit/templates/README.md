<p align="center">
  <img src="deploy_toolkit/logo_img/dark_logo_banner.png" width="900"/>
  <br>
  <em>Analyst Toolkit · Project README</em>
  <br>
  <sub>Generated by the deploy toolkit</sub>
  <br>
  <img alt="MIT License" src="https://img.shields.io/badge/license-MIT-blue">
  <img alt="Status" src="https://img.shields.io/badge/status-active-brightgreen">
  <img alt="Version" src="https://img.shields.io/badge/toolkit-v0.2.x-blueviolet">
</p>

## Project Overview

Briefly describe your project goals and dataset here.

## Quick Start

1) Create env (Conda recommended):
```bash
conda env create -f environment.yml -n <env>
conda activate <env>
```

2) Common make targets:
```bash
# If you just unzipped the bundle, call the toolkit Makefile directly:
make -f deploy_toolkit/Makefile project PROJECT_NAME=<name> DATASET=auto ENV=<env>

# After setup, a root Makefile delegator is created, so you can use:
make help
make notebook
make configs INPUT=data/raw/your.csv
```

Targets (summary):
- project: scaffold + env + configs (alias of setup)
- setup: same as project
- notebook: open Jupyter Lab for the starter notebook
- wire-data: update `config/run_toolkit_config.yaml:pipeline_entry_path`
- configs: generate config suggestions under `config/generated/`
- package: build `deploy_bundle.zip` containing only `deploy_toolkit/`

Notes
- Place a CSV at repo root or `data/raw/` before running `project`.
- Kernel name defaults to `Python (<env>)`. Change with `KERNEL_NAME="..."`.
- Ingestion defaults to copying a root CSV into `data/raw/` (set `INGEST=none` to skip).

## CLI Run

After setup and config review, you can run the pipeline via CLI:
```bash
python -m analyst_toolkit.run_toolkit_pipeline --config config/run_toolkit_config.yaml
```

## License

MIT — see LICENSE if included in your project.
